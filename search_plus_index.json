{"./":{"url":"./","title":"Machine Learning With Go","keywords":"","body":"机器学习 - Go 翻译名 原名：Machine Learning With Go 译名：机器学习 - Go 翻译来源 Book: Machine Learning With Go PDF: Machine Learning With Go Github Source Code Bilibili Video 使用Go做机器学习 Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"wiki/machine-learning-with-go/table-of-contents.html":{"url":"wiki/machine-learning-with-go/table-of-contents.html","title":"目录","keywords":"","body":"目录 Table of Contents Preface [Page 18-30, 12] What this book covers What you need for this book Who this book is for Conventions Reader feedback Customer support Downloading the example code Downloading the color images of this book Errata Piracy Questions Chapter 01. Gathering and Organizing Data [Page 31-69, 38] Handling data - Gopher style Best practices for gathering and organizing data with Go CSV files Reading in CSV data from a file Handling unexpected fields Handling unexpected types Manipulating CSV data with data frames JSON Parsing JSON JSON output SQL-like databases Connecting to an SQL database Querying the database Modifying the database Caching Caching data in memory Caching data locally on disk Data versioning Pachyderm jargon Deploying/installing Pachyderm Creating data repositories for data versioning Putting data into data repositories Getting data out of versioned data repositories References Summary Chapter 02. Matrices, Probability, and Statistics [Page 70-105, 35] Matrices and vectors Vectors Vector operations Matrices Matrix operations Statistics Distributions Statistical measures Measures of central tendency Measures of spread or dispersion Visualizing distributions Histograms Box plots Probability Random variables Probability measures Independent and conditional probability Hypothesis testing Test statistics Calculating p-values References Summary Chapter 03. Evaluation and Validation [Page 105-131, 26] Evaluation Continuous metrics Categorical metrics Individual evaluation metrics for categorical variablesConfusion matrices, AUC, and ROC Validation Training and test sets Holdout set Cross validation References Summary Chapter 04. Regression [Page 132-165, 33] Understanding regression model jargon Linear regression Overview of linear regression Linear regression assumptions and pitfalls Linear regression example Profiling the data Choosing our independent variable Creating our training and test sets Training our model Evaluating the trained model Multiple linear regression Nonlinear and other types of regression References Summary Chapter 05. Classification [Page 166-205, 39] Understanding classification model jargon Logistic regression Overview of logistic regression Logistic regression assumptions and pitfalls Logistic regression example Cleaning and profiling the data Creating our training and test sets Training and testing the logistic regression model k-nearest neighbors Overview of kNN kNN assumptions and pitfalls kNN example Decision trees and random forests Overview of decision trees and random forests Decision tree and random forest assumptions and pitfalls Decision tree example Random forest example Naive bayes Overview of naive bayes and its big assumption Naive bayes example References Summary Chapter 06. Clustering [Page 206-234, 28] Understanding clustering model jargon Measuring Distance or Similarity Evaluating clustering techniques Internal clustering evaluation External clustering evaluation k-means clustering Overview of k-means clustering k-means assumptions and pitfalls k-means clustering example Profiling the data Generating clusters with k-means Evaluating the generated clusters Other clustering techniques References Summary Chapter 07. Time Series and Anomaly Detection [Page 235-267, 32] Representing time series data in Go Understanding time series jargon Statistics related to time series Autocorrelation Partial autocorrelation Auto-regressive models for forecasting Auto-regressive model overview Auto-regressive model assumptions and pitfalls Auto-regressive model example Transforming to a stationary series Analyzing the ACF and choosing an AR order Fitting and evaluating an AR(2) model Auto-regressive moving averages and other time series models Anomaly detection References Summary Chapter 08. Neural Networks and Deep Learning [Page 268-301, 33] Understanding neural net jargon Building a simple neural network Nodes in the network Network architecture Why do we expect this architecture to work? Training our neural network Utilizing the simple neural network Training the neural network on real data Evaluating the neural network Introducing deep learning What is a deep learning model? Deep learning with Go Setting up TensorFlow for use with Go Retrieving and calling a pretrained TensorFlow model Object detection using TensorFlow from Go References Summary Chapter 09. Deploying and Distributing Analyses and Models [Page 302-341, 39] Running models reliably on remote machines A brief introduction to Docker and Docker jargon Docker-izing a machine learning application Docker-izing the model training and export Docker-izing model predictions Testing the Docker images locally Running the Docker images on remote machines Building a scalable and reproducible machine learning pipeline Setting up a Pachyderm and Kubernetes cluster Building a Pachyderm machine learning pipeline Creating and filling the input repositories Creating and running the processing stages Updating pipelines and examining provenance Scaling pipeline stages References Summary Chapter 10. Algorithms/Techniques Related to Machine Learning [Page 342-351, 9] Gradient descent Entropy, information gain, and related methods Backpropagation Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"wiki/machine-learning-with-go/preface.html":{"url":"wiki/machine-learning-with-go/preface.html","title":"前言","keywords":"","body":"机器学习 -Go 翻译名 原名：Machine Learning With Go 译名：机器学习 - Go 翻译来源 Book: Machine Learning With Go PDF: Machine Learning With Go Github Source Code Bilibili Video 使用Go做机器学习 Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"wiki/machine-learning-with-go/":{"url":"wiki/machine-learning-with-go/","title":"Chapter 01 - 收集和整理数据","keywords":"","body":"机器学习 -Go 翻译名 原名：Machine Learning With Go 译名：机器学习 - Go 翻译来源 Book: Machine Learning With Go PDF: Machine Learning With Go Github Source Code Bilibili Video 使用Go做机器学习 Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"wiki/machine-learning-with-go/chapter02/":{"url":"wiki/machine-learning-with-go/chapter02/","title":"Chapter 02 - 矩阵，概率和统计","keywords":"","body":"矩阵，概率和统计 Matrices, Probability, and Statistics [Page 71-105, 34] 尽管在本书中我们将采用一种最实用/应用的方法进行机器学习，但是某些基本主题对于理解和正确地应用机器学习至关重要。特别是，对概率和统计量的基本了解将使我们能够将某些算法与相关问题进行匹配，了解我们的数据和结果，并对数据进行必要的转换。然后，矩阵和一些线性代数将使我们能够正确地表示我们的数据，并实现优化，最小化和基于矩阵的变换。 如果您对数学或统计数据有些生疏，请不要担心太多。我们将在这里介绍一些基础知识，并向您展示如何以编程方式使用相关的统计量度和矩阵技术，这些将在本书的后面部分进行介绍。话虽如此，这不是一本有关统计，概率和线性代数的书。为了真正精通机器学习，应该花一些时间在更深的层次上学习这些主题。 Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"wiki/machine-learning-with-go/chapter02/matrices-and-vectors.html":{"url":"wiki/machine-learning-with-go/chapter02/matrices-and-vectors.html","title":"矩阵和向量","keywords":"","body":"xx 矩阵和向量 如果您花费大量时间学习和应用机器学习，则会看到大量关于矩阵和向量的引用。 实际上，许多机器学习算法都归结为一系列针对矩阵的迭代运算。 什么是矩阵和向量，以及我们如何在Go程序中表示它们？ 在大多数情况下，我们将使用github.com/gonum中的包来形成和使用矩阵和向量。 这是一系列专注于数值计算的Go软件包，而且它们一直在变得越来越好。 向量 向量是数字的有序集合，以行（从左到右）或列（上和下）排列。 向量中的每个数字称为分量。 例如，这可能是代表我们公司销售的数字的集合，或者可能是代表温度的数字的集合。 当然，使用Go slice表示这些有序的数据集合是很自然的，如下所示 // Initialize a \"vector\" via a slice. var myvector []float64 // Add a couple of components to the vector. myvector = append(myvector, 11.0) myvector = append(myvector, 5.2) // Output the results to stdout. fmt.Println(myvector) 切片确实是有序集合。 但是，它们并不能真正代表行或列的概念，我们仍然需要在切片之上计算出各种矢量运算。 幸运的是，在向量运算方面，gonum提供了gonum.org/v1/gonum/floats来对float64值的切片和gonum.org/v1/gonum/mat进行运算，该运算符与矩阵一起提供了Vector类型（具有相应的方法） // Create a new vector value. myvector := mat.NewVector(2, []float64{11.0, 5.2}) 向量运算 如此处所述，使用向量必须使用某些特定于向量/矩阵的操作和规则。 例如，如何将向量相乘？ 我们如何知道两个向量是否相似？ gonum.org/v1/gonum/floats和gonum.org/v1/gonum/mat提供用于矢量/切片操作的内置方法和功能，例如点积，排序和距离。 我们将在这里不介绍所有功能，因为有很多功能，但是我们可以对使用向量的能力有一个大致的了解。 首先，我们可以按照以下方式使用gonum.org/v1/gonum/floats // Initialize a couple of \"vectors\" represented as slices. vectorA := []float64{11.0, 5.2, -1.3} vectorB := []float64{-7.2, 4.2, 5.1} // Compute the dot product of A and B // (https://en.wikipedia.org/wiki/Dot_product). dotProduct := floats.Dot(vectorA, vectorB) fmt.Printf(\"The dot product of A and B is: %0.2f\\n\", dotProduct) // Scale each element of A by 1.5. floats.Scale(1.5, vectorA) fmt.Printf(\"Scaling A by 1.5 gives: %v\\n\", vectorA) // Compute the norm/length of B. normB := floats.Norm(vectorB, 2) fmt.Printf(\"The norm/length of B is: %0.2f\\n\", normB) 我们也可以使用 gonum.org/v1/gonum/mat: // Initialize a couple of \"vectors\" represented as slices. vectorA := mat.NewVector(3, []float64{11.0, 5.2, -1.3}) vectorB := mat.NewVector(3, []float64{-7.2, 4.2, 5.1}) // Compute the dot product of A and B // (https://en.wikipedia.org/wiki/Dot_product). dotProduct := mat.Dot(vectorA, vectorB) fmt.Printf(\"The dot product of A and B is: %0.2f\\n\", dotProduct) // Scale each element of A by 1.5. vectorA.ScaleVec(1.5, vectorA) fmt.Printf(\"Scaling A by 1.5 gives: %v\\n\", vectorA) // Compute the norm/length of B. normB := blas64.Nrm2(3, vectorB.RawVector()) fmt.Printf(\"The norm/length of B is: %0.2f\\n\", normB) 两种情况下的语义相似。 如果您仅使用向量（非矩阵）和/或只需要对的切片进行一些轻量和快速的操作 浮动，那么gonum.org/v1/gonum/floatsis可能是一个不错的选择。 但是，如果您同时使用矩阵和向量，并且/或者想使用更广泛的向量/矩阵功能，则最好使用gonum.org/v1/gonum/mat（以及偶尔引用gonum.org/ v1 / gonum / blas / blas64）。 矩阵 矩阵和线性代数对许多人来说似乎很复杂，但是简单地说，矩阵只是数字的矩形组织，线性代数决定了与之相关的规则。 例如，数字A排列在4 x 3矩形上的矩阵A可能看起来像这样 \\begin{bmatrix} {a_{11}}&{a_{12}}&{a_{13}}&{a_{14}}\\\\ {a_{21}}&{a_{22}}&{a_{23}}&{a_{24}}\\\\ {a_{31}}&{a_{32}}&{a_{23}}&{a_{34}}\\\\ {a_{41}}&{a_{42}}&{a_{23}}&{a_{44}}\\\\ \\end{bmatrix} A的组成部分（a11，a12等）是我们排列到矩阵中的单个数字，下标表示组成部分在矩阵中的位置。 第一个索引是行索引，第二个索引是列索引。 更一般而言，A可以具有M行和N列的任何形状/大小: \\begin{bmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1N}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2N}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {a_{M1}}&{a_{M2}}&{\\cdots}&{a_{MN}}\\\\ \\end{bmatrix} 为了使用gonum.org/v1/gonum/mat形成这样的矩阵，我们需要创建一个切片offloat64值，该值是所有矩阵组件的平面表示。 例如，在我们的示例中，我们要形成以下矩阵: \\begin{matrix} 1.2&-5.7\\\\ -2.4&7.3\\\\ \\end{matrix} 我们将需要如下创建一个float64值切片: // Create a flat representation of our matrix. components := []float64{1.2, -5.7, -2.4, 7.3} 然后，我们可以提供此信息以及尺寸信息togonum.org/v1/gonum/mat以形成一个新的mat.Dense矩阵值： // Form our matrix (the first argument is the number of // rows and the second argument is the number of columns). a := mat.NewDense(2, 2, data) // As a sanity check, output the matrix to standard out. fa := mat.Formatted(a, mat.Prefix(\" \")) fmt.Printf(\"mat = %v\\n\\n\", fa) 请注意，我们还在gonum.org/v1/gonum/mat中使用了漂亮的格式化逻辑来打印矩阵以进行完整性检查。 运行此命令时，应该看到以下内容： $ go build $ ./myprogram A = [ 1.2 -5.7] [-2.4 7.3] 然后，我们可以通过内置方法访问和修改A中的某些值： // Get a single value from the matrix. val := a.At(0, 1) fmt.Printf(\"The value of a at (0,1) is: %.2f\\n\\n\", val) // Get the values in a specific column. col := mat.Col(nil, 0, a) fmt.Printf(\"The values in the 1st column are: %v\\n\\n\", col) // Get the values in a kspecific row. row := mat.Row(nil, 1, a) fmt.Printf(\"The values in the 2nd row are: %v\\n\\n\", row) // Modify a single element. a.Set(0, 1, 11.2) // Modify an entire row. a.SetRow(0, []float64{14.3, -4.2}) // Modify an entire column. a.SetCol(0, []float64{1.7, -0.3}) 矩阵运算 与向量一样，矩阵也有自己的一组算术规则，以及全部特殊操作集。 与矩阵相关的某些算法的行为与您期望的类似。 但是，在做诸如将矩阵相乘或求逆之类的事情时，您需要特别小心。 方便地，gonum.org/v1/gonum/mat为此算法和许多其他特殊操作提供了一个不错的API。 这是显示一些操作的示例，例如加，乘，除等: // Create two matrices of the same size, a and b. a := mat.NewDense(3, 3, []float64{1, 2, 3, 0, 4, 5, 0, 0, 6}) b := mat.NewDense(3, 3, []float64{8, 9, 10, 1, 4, 2, 9, 0, 2}) // Create a third matrix of a different size. c := mat.NewDense(3, 2, []float64{3, 2, 1, 4, 0, 8}) // Add a and b. d := mat.NewDense(0, 0, nil) d.Add(a, b) fd := mat.Formatted(d, mat.Prefix(\" \")) fmt.Printf(\"d = a + b = %0.4v\\n\\n\", fd) // Multiply a and c. f := mat.NewDense(0, 0, nil) f.Mul(a, c) ff := mat.Formatted(f, mat.Prefix(\" \")) fmt.Printf(\"f = a c = %0.4v\\n\\n\", ff) // Raising a matrix to a power. g := mat.NewDense(0, 0, nil) g.Pow(a, 5) fg := mat.Formatted(g, mat.Prefix(\" \")) fmt.Printf(\"g = a^5 = %0.4v\\n\\n\", fg) // Apply a function to each of the elements of a. h := mat.NewDense(0, 0, nil) sqrt := func(_, _ int, v float64) float64 { return math.Sqrt(v) } h.Apply(sqrt, a) fh := mat.Formatted(h, mat.Prefix(\" \")) fmt.Printf(\"h = sqrt(a) = %0.4v\\n\\n\", fh) 特别要注意上面的Apply（）方法。 此功能非常有用，因为它允许您将任何功能应用于矩阵的元素。 您可以将相同的函数应用于所有元素，或者使函数依赖于矩阵元素的索引。 例如，您可以使用此方法执行逐个元素 乘法，用户定义功能的应用或第三方程序包中的功能的应用。 然后，对于所有事物，例如行列式，特征值/向量解算器和逆函数，gonum.org / v1 / gonum / mathas都已介绍。 同样，我不会扩展所有功能，但是这里是一些操作的示例： // Create a new matrix a. a := mat.NewDense(3, 3, []float64{1, 2, 3, 0, 4, 5, 0, 0, 6}) // Compute and output the transpose of the matrix. ft := mat.Formatted(a.T(), mat.Prefix(\" \")) fmt.Printf(\"a^T = %v\\n\\n\", ft) // Compute and output the determinant of a. deta := mat.Det(a) fmt.Printf(\"det(a) = %.2f\\n\\n\", deta) // Compute and output the inverse of a. aInverse := mat.NewDense(0, 0, nil) if err := aInverse.Inverse(a); err != nil { log.Fatal(err) } fi := mat.Formatted(aInverse, mat.Prefix(\" \")) fmt.Printf(\"a^-1 = %v\\n\\n\", fi) 请注意，在此示例中，当我们需要确保保持完整性和可读性时，我们利用Go的显式错误处理功能。 矩阵并不总是有逆的。 处理矩阵和大型数据集时，会出现各种情况，我们希望确保我们的应用程序符合预期。 Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"wiki/machine-learning-with-go/chapter02/statistics.html":{"url":"wiki/machine-learning-with-go/chapter02/statistics.html","title":"统计","keywords":"","body":"统计 归根结底，机器学习应用程序的成功将取决于数据的质量，对数据的理解以及对结果的评估/验证。 所有这三件事都要求我们对统计数据有所了解。 统计领域有助于我们了解我们的数据，并量化我们的数据和结果。 它还为我们提供了一些机制，以衡量我们的应用程序的性能如何，并防止某些机器学习陷阱（例如过拟合）。 与线性代数一样，我们无法在此处对统计进行完整介绍，但是在线和印刷版中有许多资源可供学习入门统计。在这里，我们将着重于对基础知识的基本理解以及在Linux中实现的实用性。 走。 我们将介绍分布的概念，以及对这些分布进行量化和可视化的介绍。 分布 分布表示值在数据集中出现的频率。例如，假设您作为数据科学家正在跟踪的一件事是某项产品或服务的每日销售额，并且您有一长串（可以表示为矢量或矩阵的一部分）清单数字。这些销售数字是我们数据集的一部分，其中包括一天的销售额为121美元，另一天的销售额为207美元，依此类推。 在我们累积的销售数量中，有一个销售数量是最低的。在我们已累积的销售编号中，也将有一个最高的销售编号，而其余的销售编号则介于两者之间（至少，如果我们假设没有确切的重复编号）。下图显示了这些销售价值的低，高和中间值：因此，这是销售的分布，或者至少是销售分布的一种表示。请注意，此分布具有数量较多的区域和数量稀疏的区域。另外，请注意，数字似乎在分布的中心附近是有倾向性的。 因此，这是销售的分布，或销售分布的至少一种表示。 请注意，此分布具有数量较多的区域和数量稀疏的区域。 另外，请注意，数字似乎在分布的中心附近是有倾向性的。 统计量度 为了量化分布的样子，我们将使用各种统计量度。通常，这些量度有两种类型： 1.集中趋势度量：这些度量衡量大多数值的位置或分布中心的位置（例如，沿着前面的线性表示）。 2.散布或散布度量：这些度量用于衡量分布的值如何分布在分布的范围内（从最低值到最高值）。 有多种软件包可让您快速计算和/或利用这些统计量度。 我们将使用gonum.org/v1/gonum/stat（您可能开始注意到我们将大量使用gonum）和github.com/montanaflynn/stats。 请注意，thegonum.org / v1 / gonum / statandgithub.com / montanaflynn / statspackages的名称存在一个字母差异，请注意以下各节中的示例。 集中趋势的量度 集中趋势的度量包括： Mean: 这就是您通常所说的平均值。 我们通过对分布中的所有数字求和，然后除以数字数来计算。 Median: 如果我们将分布中的所有数字从最低到最高进行排序，则该数字将数字的最低一半与数字的最高一半分隔开。 Mode: 这是分布中最频繁出现的值。 让我们针对第1章“收集和组织数据”中先前介绍的虹膜数据集的一列中的值计算这些度量。 提醒一下，此数据集包括四列花朵测量值，以及一列相应的花卉种类。 因此，每个度量值列都包含代表该度量值分布的一组值： // Open the CSV file. irisFile, err := os.Open(\"../data/iris.csv\") if err != nil { log.Fatal(err) } defer irisFile.Close() // Create a dataframe from the CSV file. irisDF := dataframe.ReadCSV(irisFile) // Get the float values from the \"sepal_length\" column as // we will be looking at the measures for this variable. sepalLength := irisDF.Col(\"sepal_length\").Float() // Calculate the Mean of the variable. meanVal := stat.Mean(sepalLength, nil) // Calculate the Mode of the variable. modeVal, modeCount := stat.Mode(sepalLength, nil) // Calculate the Median of the variable. medianVal, err := stats.Median(sepalLength) if err != nil { log.Fatal(err) } // Output the results to standard out. fmt.Printf(\"\\nSepal Length Summary Statistics:\\n\") fmt.Printf(\"Mean value: %0.2f\\n\", meanVal) fmt.Printf(\"Mode value: %0.2f\\n\", modeVal) fmt.Printf(\"Mode count: %d\\n\", int(modeCount)) fmt.Printf(\"Median value: %0.2f\\n\\n\", medianVal) 运行此程序将导致以下结果： $ go build $ ./myprogram Sepal Length Summary Statistics: Mean value: 5.84 Mode value: 5.00 Mode count: 10 Median value: 5.80 您可以看到均值，众数和中位数略有不同。 但是，请注意，sepal_length列中的值的平均值和中位数非常接近。 另一方面，如果在前面的代码中将sepal_length更改为花瓣长度，我们将得到以下结果： $ go build $ ./myprogram Sepal Length Summary Statistics: Mean value: 3.76 Mode value: 1.50 Mode count: 14 Median value: 4.35 对于petal_length值，平均值和中位数不太接近。 我们已经可以从该信息中获得一些有关数据的直觉。 如果平均值和中位数不接近，则意味着较高或较低的值分别拖累了平均值的较高或较低-这种影响在中位数中不那么明显。 我们称其为偏态分布。 扩散或分散措施 现在，我们对大多数值位于何处（或分布的中心）有了一个想法，让我们尝试量化分布的值如何分布在分布中心附近。 量化这一点的一些广泛使用的措施如下： Maximum: 最高分布值 Minimum: 最低分布值 Range: 最大值和最小值之间的差异 Variance: 通过获取分布中的每个值，从分布的均值计算每个人的差异，对该差异进行平方，将其与其他平方差相加并除以分布中的值数量来计算此度量 Standard deviation: 方差的平方根 Quantiles/quartiles: 与中位数相似，这些度量定义了分布中的临界点，其中一定数量的较低值低于该度量，而一定数量较高的值高于该度量 使用gonum.org/v1/gonum/stat，这些度量的计算如下： // Open the CSV file. irisFile, err := os.Open(\"../data/iris.csv\") if err != nil { log.Fatal(err) } defer irisFile.Close() // Create a dataframe from the CSV file. irisDF := dataframe.ReadCSV(irisFile) // Get the float values from the \"sepal_length\" column as // we will be looking at the measures for this variable. sepalLength := irisDF.Col(\"petal_length\").Float() // Calculate the Max of the variable. minVal := floats.Min(sepalLength) // Calculate the Max of the variable. maxVal := floats.Max(sepalLength) // Calculate the Median of the variable. rangeVal := maxVal - minVal // Calculate the variance of the variable. varianceVal := stat.Variance(sepalLength, nil) // Calculate the standard deviation of the variable. stdDevVal := stat.StdDev(sepalLength, nil) // Sort the values. inds := make([]int, len(sepalLength)) floats.Argsort(sepalLength, inds) // Get the Quantiles. quant25 := stat.Quantile(0.25, stat.Empirical, sepalLength, nil) quant50 := stat.Quantile(0.50, stat.Empirical, sepalLength, nil) quant75 := stat.Quantile(0.75, stat.Empirical, sepalLength, nil) // Output the results to standard out. fmt.Printf(\"\\nSepal Length Summary Statistics:\\n\") fmt.Printf(\"Max value: %0.2f\\n\", maxVal) fmt.Printf(\"Min value: %0.2f\\n\", minVal) fmt.Printf(\"Range value: %0.2f\\n\", rangeVal) fmt.Printf(\"Variance value: %0.2f\\n\", varianceVal) fmt.Printf(\"Std Dev value: %0.2f\\n\", stdDevVal) fmt.Printf(\"25 Quantile: %0.2f\\n\", quant25) fmt.Printf(\"50 Quantile: %0.2f\\n\", quant50) fmt.Printf(\"75 Quantile: %0.2f\\n\\n\", quant75) 运行此程序将得到以下结果： $ go build $ ./myprogram Sepal Length Summary Statistics: Max value: 6.90 Min value: 1.00 Range value: 5.90 Variance value: 3.11 Std Dev value: 1.76 25 Quantile: 1.60 50 Quantile: 4.30 75 Quantile: 5.10 好的，让我们尝试遍历这些数字，看看它们对sepal_length列中值分布的含义。 我们可以得出以下结论。 首先，标准偏差为1.76，整个值范围为5.90。 与方差相反，标准偏差与值本身具有相同的单位，因此我们可以看到，这些值实际上在值范围内变化很大（标准偏差值约为值总范围的30％） 。 接下来，让我们看一下分位数。 25％的分位数代表分布中的一个点，其中分布中的25％的值低于度量值，而其他75％的值高于度量值。 对于50％和75％的分位数，这是相似的。 由于25％的分位数比75％的分位数与最大值之间的距离更接近最小值，因此我们可以推断出分布中的较高值比较低值更容易散开。 当然，您可以将这些度量与集中趋势度量结合起来使用，以帮助您量化分布的外观，并且这里没有涵盖其他统计度量。 Tips: 这里的要点是，您应该利用这些措施来帮助您建立数据的思维模型。 这将使您能够根据上下文和理智来检查工作。 可视化分布 尽管量化分配的外观很重要，但实际上我们应该可视化分配以获取最大的直觉。 有多种类型的图和图形可让我们创建值分布的可视表示形式，这有助于我们形成数据的心理模型并将有关我们的数据的信息传达给我们团队的其他成员，我们的应用程序用户等 上。 直方图 Histograms 这些可以帮助我们理解分布的图形或图表的第一种类型称为直方图。 实际上，直方图实际上是组织或计算值的某种方式，然后可以将其绘制在直方图中。 为了形成直方图，我们首先创建一定数量的bin，在我们的值的总范围内切出不同的区域。 例如，以前面几节中讨论的销售数量分布为例：下一步，我们计算每个分类中有多少值：这些计数与分类的定义一起构成直方图。 我们可以轻松地将其转换为计数图，这可以很好地直观显示我们的分布：我们可以再次使用gonum从实际数据创建直方图并绘制直方图。 可以在gonum.org/v1/plot中找到gonum提供的用于此类绘图的软件包以及其他类型的绘图。 作为一个例子，让我们创建 接下来，我们计算以下每个箱中有多少值： 这些计数与垃圾箱的定义一起构成我们的直方图。 我们可以轻松地将其转换为计数图，这可以很好地直观显示我们的分布： 我们可以再次使用gonum从实际数据创建直方图并绘制直方图。 可以在gonum.org/v1/plot中找到gonum提供的用于此类绘图的软件包以及其他类型的绘图。 作为一个例子，让我们创建虹膜数据集中每个列的直方图。 首先，从gonum导入以下内容： import ( \"gonum.org/v1/plot\" \"gonum.org/v1/plot/plotter\" \"gonum.org/v1/plot/vg\" ) 然后，我们将读取虹膜数据集，创建一个数据框，并查看生成直方图的数值列： // Open the CSV file. irisFile, err := os.Open(\"../data/iris.csv\") if err != nil { log.Fatal(err) } defer irisFile.Close() // Create a dataframe from the CSV file. irisDF := dataframe.ReadCSV(irisFile) // Create a histogram for each of the feature columns in the dataset. for _, colName := range irisDF.Names() { // If the column is one of the feature columns, let's create // a histogram of the values. if colName != \"species\" { // Create a plotter.Values value and fill it with the // values from the respective column of the dataframe. v := make(plotter.Values, irisDF.Nrow()) for i, floatVal := range irisDF.Col(colName).Float() { v[i] = floatVal } // Make a plot and set its title. p, err := plot.New() if err != nil { log.Fatal(err) } p.Title.Text = fmt.Sprintf(\"Histogram of a %s\", colName) // Create a histogram of our values drawn // from the standard normal. h, err := plotter.NewHist(v, 16) if err != nil { log.Fatal(err) } // Normalize the histogram. h.Normalize(1) // Add the histogram to the plot. p.Add(h) // Save the plot to a PNG file. if err := p.Save(4*vg.Inch, 4*vg.Inch, colName+\"_hist.png\"); err != nil { log.Fatal(err) } } } 请注意，我们已经标准化了直方图（使用h.Normalize（））。 这是典型的原因，因为经常需要比较具有不同计数值的不同分布。 直方图归一化允许我们并排比较不同的分布 前面的代码将为虹膜数据集中的数字列生成四个带有以下直方图的* .png文件： 这些分布中的每一个看起来都与其他分布不同。 sepal_width分布看起来像钟形曲线或正态/高斯分布（我们将在本书后面讨论）。 另一方面，花瓣分布看起来好像它们具有两个不同的不同值簇。 在以后开发机器学习工作流时，我们将利用这些观察结果，但是目前，仅 请注意这些可视化如何能够帮助我们建立数据的心理模型。 箱形图 直方图绝不是从视觉上了解我们的数据的唯一方法。 另一种常用的绘图类型称为箱形绘图。 这种类型的图还使我们对分布中的值的分组和散布有了一个想法，但是与直方图相反，箱形图具有几个可帮助引导眼睛的明显特征： Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"wiki/formula.html":{"url":"wiki/formula.html","title":"Markdown 公式","keywords":"","body":"公式 在Markdown中输入数学公式(MathJax) 1 \\[ x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a} \\] 2 \\begin{bmatrix} {a_{11}}&{a_{12}}&{\\cdots}&{a_{1n}}\\\\ {a_{21}}&{a_{22}}&{\\cdots}&{a_{2n}}\\\\ {\\vdots}&{\\vdots}&{\\ddots}&{\\vdots}\\\\ {a_{m1}}&{a_{m2}}&{\\cdots}&{a_{mn}}\\\\ \\end{bmatrix} Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "},"tags.html":{"url":"tags.html","title":"tags","keywords":"","body":"Tags Copyright © 2015-present airdb.            LastUpdated: 2020-01-14 16:07:48 "}}